import pandas as pd
import numpy as np
import joblib
from sklearn.metrics import accuracy_score, top_k_accuracy_score

# âœ… ë°ì´í„° ë¡œë”© ë° ë¼ë²¨ ìƒì„±
df = pd.read_csv("./data/test_data.csv")
df["Position_Label"] = df["Position_X"].astype(str) + "_" + df["Position_Y"].astype(str)

# âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸°
bundle = joblib.load("model_and_encoder.pkl")
model = bundle["model"]
le = bundle["label_encoder"]
scaler = bundle["scaler"]
feature_cols = bundle["feature_columns"]

# âœ… ë¼ë²¨ ì¸ì½”ë”©
df["Label_encoded"] = le.transform(df["Position_Label"])

# âœ… ì…ë ¥ ì •ê·œí™”
X = scaler.transform(df[feature_cols])
y_true = df["Label_encoded"]

# âœ… ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X)
y_proba = model.predict_proba(X)
y_pred_label = le.inverse_transform(y_pred)
y_true_label = le.inverse_transform(y_true)

# âœ… ìœ„ì¹˜ ì˜¤ì°¨ ê³„ì‚°
def coord_from_label(label):
    x, y = map(int, label.split("_"))
    return np.array([x, y])

errors = [
    np.linalg.norm(coord_from_label(p) - coord_from_label(t))
    for p, t in zip(y_pred_label, y_true_label)
]

# âœ… ê²°ê³¼ ì €ì¥
df['Pred_Label'] = y_pred_label
df['True_Label'] = y_true_label
df['Top1_Correct'] = df['Pred_Label'] == df['True_Label']
df['Position_Error'] = errors

# âœ… Top-3 ì •ë‹µ í¬í•¨ ì—¬ë¶€
top3_correct = []
for true_idx, proba in zip(y_true, y_proba):
    top3 = np.argsort(proba)[-3:][::-1]
    top3_correct.append(true_idx in top3)
df['Top3_Correct'] = top3_correct

# âœ… ê²°ê³¼ ë¶„ë¥˜
df_top1 = df[df['Top1_Correct']]
df_top3_only = df[(df['Top3_Correct']) & (~df['Top1_Correct'])]
df_wrong = df[~df['Top3_Correct']]

# âœ… ì „ì²´ ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
print("\nğŸ“Š ì˜ˆì¸¡ ì„±ëŠ¥ ìš”ì•½")
print("=" * 40)
print(f"ğŸ¯ Top-1 ì •í™•ë„: {df['Top1_Correct'].mean():.2%} ({len(df_top1)} / {len(df)})")
print(f"ğŸ” Top-3 ì •í™•ë„: {df['Top3_Correct'].mean():.2%} ({len(df[df['Top3_Correct']])} / {len(df)})")
print(f"ğŸ“ í‰ê·  ìœ„ì¹˜ ì˜¤ì°¨: {df['Position_Error'].mean():.2f} ì…€")

# âœ… ì •ë‹µ ê·¸ë£¹ë³„ ì¶œë ¥
print("\nğŸ¯ ì •í™•íˆ ë§ì¶˜ ìƒ˜í”Œ (Top-1)")
print(df_top1[['True_Label', 'Pred_Label', 'Position_Error']].head(10))

print("\nğŸ”„ Top-3 ì•ˆì— ìˆì§€ë§Œ Top-1ì€ í‹€ë¦° ìƒ˜í”Œ")
print(df_top3_only[['True_Label', 'Pred_Label', 'Position_Error']].head(10))

print("\nâŒ Top-3ì—ë„ ëª» ë“¤ì–´ê°„ ìƒ˜í”Œ")
print(df_wrong[['True_Label', 'Pred_Label', 'Position_Error']].head(10))

# âœ… ìœ„ì¹˜ë³„ ìƒì„¸ ì˜¤ì¸ì‹ ë¶„ì„
detailed_summary = []

for label in df['True_Label'].unique():
    subset = df[df['True_Label'] == label]
    count = len(subset)
    top1_acc = subset['Top1_Correct'].mean()
    top3_acc = subset['Top3_Correct'].mean()
    avg_error = subset['Position_Error'].mean()

    # ì˜¤ë‹µë§Œ ì¶”ì¶œí•´ì„œ ì–´ë””ë¡œ ë§ì´ ì˜ëª» ê°”ëŠ”ì§€ í™•ì¸
    wrong_subset = subset[~subset['Top1_Correct']]
    top_wrong_preds = (
        wrong_subset['Pred_Label'].value_counts()
        .head(3)
        .to_dict()
    )

    detailed_summary.append({
        "True_Label": label,
        "Sample_Count": count,
        "Top1_Accuracy": top1_acc,
        "Top3_Accuracy": top3_acc,
        "Avg_Position_Error": avg_error,
        "Top_Misclass_1": list(top_wrong_preds.keys())[0] if len(top_wrong_preds) > 0 else None,
        "Top_Misclass_1_Count": list(top_wrong_preds.values())[0] if len(top_wrong_preds) > 0 else 0,
        "Top_Misclass_2": list(top_wrong_preds.keys())[1] if len(top_wrong_preds) > 1 else None,
        "Top_Misclass_2_Count": list(top_wrong_preds.values())[1] if len(top_wrong_preds) > 1 else 0,
        "Top_Misclass_3": list(top_wrong_preds.keys())[2] if len(top_wrong_preds) > 2 else None,
        "Top_Misclass_3_Count": list(top_wrong_preds.values())[2] if len(top_wrong_preds) > 2 else 0
    })

# âœ… DataFrame ì •ë¦¬ ë° ì¶œë ¥
detailed_df = pd.DataFrame(detailed_summary).sort_values(by="True_Label")

# âœ… ì¶œë ¥
print("\nğŸ“Œ ìœ„ì¹˜ë³„ ì˜¤ì¸ì‹ ìƒì„¸ ë¶„ì„")
print("=" * 50)
for _, row in detailed_df.iterrows():
    print(f"ğŸ“ ìœ„ì¹˜: {row['True_Label']}")
    print(f"   - ìƒ˜í”Œ ìˆ˜: {row['Sample_Count']}")
    print(f"   - Top-1 ì •í™•ë„: {row['Top1_Accuracy']:.2%}")
    print(f"   - Top-3 ì •í™•ë„: {row['Top3_Accuracy']:.2%}")
    print(f"   - í‰ê·  ìœ„ì¹˜ ì˜¤ì°¨: {row['Avg_Position_Error']:.2f} ì…€")
    print(f"   - âŒ ìì£¼ í‹€ë¦¬ëŠ” ìœ„ì¹˜:")
    if row['Top_Misclass_1']:
        print(f"       â€¢ {row['Top_Misclass_1']} ({row['Top_Misclass_1_Count']}íšŒ)")
    if row['Top_Misclass_2']:
        print(f"       â€¢ {row['Top_Misclass_2']} ({row['Top_Misclass_2_Count']}íšŒ)")
    if row['Top_Misclass_3']:
        print(f"       â€¢ {row['Top_Misclass_3']} ({row['Top_Misclass_3_Count']}íšŒ)")
    print()

