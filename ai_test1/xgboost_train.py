import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier

# âœ… ë°ì´í„° ë¡œë”© ë° ë¼ë²¨ ìƒì„±
df = pd.read_csv("./data/training_data.csv")
df["Position_Label"] = df["Position_X"].astype(str) + "_" + df["Position_Y"].astype(str)

# âœ… ë¼ë²¨ ì¸ì½”ë”©
le = LabelEncoder()
df["Label_encoded"] = le.fit_transform(df["Position_Label"])

# âœ… ì…ë ¥ í”¼ì²˜ ë° ì •ê·œí™”
X = df[["Mag_X", "Mag_Y", "Mag_Z", "Ori_X"]]
y = df["Label_encoded"]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# âœ… í•™ìŠµ/ê²€ì¦ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# âœ… XGBoost ëª¨ë¸ ì •ì˜ ë° GPU ì„¤ì • í¬í•¨
model = XGBClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.0001,
    objective="multi:softprob",
    eval_metric="mlogloss",
    tree_method="gpu_hist",        # âœ… GPU ì‚¬ìš©
    predictor="gpu_predictor",     # âœ… GPU ì‚¬ìš©
    verbosity=1,
    random_state=42
)

print("\nğŸš€ XGBoost (GPU) ëª¨ë¸ í•™ìŠµ ì‹œì‘")
model.fit(X_train, y_train)

# âœ… ëª¨ë¸ ì €ì¥
bundle = {
    "model": model,
    "label_encoder": le,
    "scaler": scaler,
    "feature_columns": ["Mag_X", "Mag_Y", "Mag_Z", "Ori_X"]
}
joblib.dump(bundle, "model_and_encoder.pkl")

# âœ… ì„±ëŠ¥ ì¶œë ¥
train_acc = accuracy_score(y_train, model.predict(X_train))
test_acc = accuracy_score(y_test, model.predict(X_test))

print("\nğŸ“Š í•™ìŠµ ì™„ë£Œ")
print("=" * 40)
print("âœ… í•™ìŠµ ì •í™•ë„: {:.2%}".format(train_acc))
print("âœ… ê²€ì¦ ì •í™•ë„: {:.2%}".format(test_acc))
print("âœ… ëª¨ë¸ê³¼ ì¸ì½”ë” ì €ì¥ ì™„ë£Œ: model_and_encoder.pkl")
